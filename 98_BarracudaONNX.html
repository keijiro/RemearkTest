<!DOCTYPE html>
<html>
  <head>
    <title>98 Barracuda ONNX</title>
    <meta charset="utf-8">
    <style>
      .remark-slide-content {
        color: white;
        background-color: black;
        font-size: 50pt;
        padding: 0px 0.5em;
      }
      .remark-code-line { font-size: 25pt; margin: 0.2em 0px; }
      p { margin: 0.5em 0px; line-height: 120%; }
      code { margin: 0px 2em; }
    </style>
  </head>
  <body>
<textarea id="source">

皆さんこんにちは。

ユニティー・テクノロジーズ・ジャパン、アドボケイトの高橋です。

---

この講演では、Unity が提供する機械学習パッケージの一つである Barracuda を紹介します。

また、そこで利用される ONNX というエコシステムについても簡単に解説します。

---

まず最初に、Barracuda とは何であるか、ざっくりとお話ししておきましょう。

Barracuda とは、すごく簡単に言うと、学習済みの機械学習モデルを実行するための、ランタイム・エンジンです。

---

Barracuda は、またの名前を "Unity Inference Engine" と言います。

その名前が表している通り、機械学習モデルの推論を専門に扱っています。

---

機械学習は「学習」と「推論」という２つのステップに大きく分けられますが、そのうちの推論だけを行うということですね。

「学習」については、他のパッケージを使って済ませておくことが前提となります。

---

さて、言葉だけで説明していてもなかなかイメージが掴みにくいと思いますので、実際に動いている所を見てもらいましょう。

---

まずはオブジェクト検出モデルとして有名な YOLO を動かしてみました。

具体的には YOLOv4 の Tiny モデルになります。

この PC は GeForce RTX 2060 SUPER を搭載していますが、だいたい 240 fps ぐらいで動いています。

---

これは MediaPipe の FaceMesh パイプラインです。

顔検出、ランドマーク検出、瞳検出などの、複数のモデルを組み合わせることで、フェーシャルトラッキングを実現しています。

---

次は同じく MediaPipe から Selfie モデルです。

これはヒューマンセグメンテーションを行うモデルで、人体の切り抜きマスクを高速に生成します。

---

これを使えば、ビデオチャットのバーチャル背景のようなものを簡単に実現できますね。

このモデルは非常に軽量で、PC 上では 400 fps 以上で動いています。

---

同じプロジェクトを、少し古めの iPhone X 上で動かしてみました。

こちらも 60fps で動かすことができています。

このように様々なプラットフォームに柔軟に対応できるのは Barracuda の強みのひとつですね。

---

では、さっそく Barracuda の解説に……と行きたいところなのですが、その前に ONNX についてお話ししておきましょう。

---

O-N-N-X, Open Neural Network Exchange, ONNX は、ものすごく簡単に言うと、機械学習モデルの共通ファイルフォーマットです。

---

機械学習には TensorFlow や PyTorch など様々なライブラリがありますが、生成されたモデルを ONNX 形式で出力することによって、様々なランタイムで使いまわすことができるようになります。

---

そして Barracuda はこの ONNX ファイル形式に対応しています。

---

つまり、TensorFlow や PyTorch で生成したモデルを ONNX 形式で出力すれば、それを Unity へインポートすることで、Unity が対応する様々なプラットフォームに展開することが可能になる……と言う理屈ですね。

---

残念ながら、これを実現するのは口で言うほど簡単ではないんですが、ひとまず、そういう理想を持って作られている、と理解してもらえればいいかなと思います。

---

では次に、簡単なサンプルを使って、実際に ONNX ファイルを Barracuda にインポートする工程をお見せしましょう。

ここにサンプルとして用意した至極小さな ONNX ファイルがあります。

---

中身はこんな感じです。

単純に convolution や rectifier を通してるだけの簡単なネットワークですね。

これを Unity にドラッグ＆ドロップ。

これでインポート完了です。

---

Barracuda は Netron に対応していて、インポートしたファイルをダブルクリックで開けます。

また、インスペクタからこのボタンを押すことで、 Barracudaの 内部表現を確認することもできます。

---

ちなみに、これは Netron と言うツールです。

ニューラルネットの視覚化を行なってくれる、非常に便利なツールです。

---

ONNX 以外の形式にも対応していて、デバッグ作業などで非常に役立ちます。

Barracuda を使用する際には是非インストールしておいてください。

---

さて、こうして ONNX ファイルのネットワークと、 Barracuda の内部表現を比較してみると、構造がだいぶ異なっていることが分かると思います。

Barracuda はインポート時に最適化を行うので、こんな風に異なった内部表現に変化することがあるんですね。

---

具体的には、事前計算可能な部分が結合されたり、２回行ってる transpose が不要になるよう調整されたり、convolution と bias と activator が一括化されたり、とか、そう言った処理がなされます。

---

実際に Barracuda を使用するサンプルコードを見てみましょう。

これは機械学習のチュートリアルとしてよく使われる、MNIST 手書き認識モデルのサンプルです。

こちらのリポジトリで公開しています。

---

主なコードは MnistTest.cs 内にあります。

中身はこんな感じです。

ごく普通の作りをした API なので、この手のライブラリを使ったことのある方なら、簡単に使いこなせるかもしれません。

---

簡単に流れを見ていきましょう。

まず、入力用のテンソルを作成します。

テンソルというのは、簡単に言ってしまえば、多次元の数値配列のことですね。

---

Unity でグラフィックスを扱う際などには、4x4 要素の２次元マトリクスなどがよく使われますが、機械学習の分野では、256x256x256 の３次元テンソルや、更に大きな４次元テンソルなどがよく使われます。

---

そういった巨大な数値配列を効率的に扱うための仕組みが用意されていると理解してください。

ただ、ここで使ってるのは 28x28 の比較的小さなテンソルですね。

MNIST は比較的小さなモデルなので、この程度の要素数で動かします。

---

ちなみに Tensor クラスは IDisposable の継承クラスです。

使わなくなったタイミングで明示的に Dispose メソッドを呼ぶか、あるいはこのように using ステートメントを使う必要があります。

---

テンソルの中身は普通の C# の多次元配列のようにアクセスできます。

入力画像のグレースケール値を１ピクセルずつ代入していますね。

---

ただ、画像の表現形式にちょっとした違いがあって、ここで Y 軸を反転させておく必要がありました。

このような表現形式の変換は、必ずと言っていいほど必要とされるので、よく覚えておいてください。

---

次に機械学習モデルを動かすための worker instance を生成します。

デバイスの種類としては CPU を指定しています。

---

ちなみに、ここを GPU に変更すれば、Compute Shader を利用して動く GPU ワーカーを生成することもできます。

このモデルは非常に小規模なので、CPU ワーカーでも十分でしょう。

---

Execute メソッドで実行したら、PeekOutput メソッドで結果を取り出します。

取得された値に対して SoftMax 関数を適用して、結果のスコアとしています。

---

SoftMax 関数は、機械学習でよく使われるお決まりの関数ですね。

このモデルの説明に、結果は SoftMax を使ってください、と書かれていたので、その通りにしてみました。

---

結果はこんな感じです。

ちゃんと手書きの数値が認識されているのが分かると思います。

---

以上が、最も簡単な Barracuda の使用例でした。

C# スクリプトを使って非常に簡単に機械学習モデルを動かすことができる、というのがお分かりいただけたと思います。

---

ただ、このような画像のプリプロセスを、シングルスレッドのナイーブな C# で動かすのは、実際にはちょっと心許ないですよね。

---

この MNIST のモデルは、入力がたかだか 28x28 なので、まだ許容できます。

ただ、例えばこれが 512x512x3 のような巨大なテンソルになってくると、話が変わってきますよね。

---

そのような場合は Compute Shader を使って GPU 側でプリプロセスを動かした方がいいでしょう。

---

そこで、同じ MNIST のモデルを、なるべく GPU 側でパイプラインを動かすよう、実装し直してみることにしました。

このサンプルはこちらのリポジトリで公開しています。

---

まず、入力テンソルを格納するためのデータ領域として ComputeTensorData を生成しています。

ComputeTensorData は Compute Buffer を使ってデータを格納するためのクラスです。

---

前のサンプルでは、デフォルトのデータ領域として CPU 側のメモリが使用されていましたが、このように明示的にデータ領域を指定することで、GPU 側のメモリを使用することが可能になります。

---

次に、入力画像をテンソルへコピーするための compute shader を実行します。

---

コンピュートシェーダーの中身はこんな感じです。

単純にテクスチャをサンプリングして配列に出力するだけなので、詳しい解説は省略します。

---

ただ、やはりここで画像の上下を反転していますね。

あと、出力先となる compute buffer は１次元配列としてしかアクセスできないので、インデクスの計算が若干ややこしくなっています。

---

入力テンソルが用意できたら、worker インスタンスを生成して、実行します。

今回は GPU で実行することが前提なので、worker の種類として GPU を指定しました。

---

推論結果は 10 要素のテンソルとなるので、そのための compute buffer を作成します。

そして、ポストプロセスを行うための compute shader を実行します。

---

Compute shader の中身はこんな感じです。

これはもう本当に SoftMax 関数を適用しているだけですね。

---

結果を格納した compute buffer は、マテリアルを介してそのまま描画用のシェーダーへ渡されます。

こうすることで、CPU を経由すること無く、そのまま描画パイプラインに流すことができます。

---

つまり、入力から出力まで、一切 CPU 側にデータを戻すことなく、 GPU 側で処理を完結させることができるというわけです。

まあ実際には、推論結果を CPU 側に戻さず完結させることは、それほど多くないかもしれません。

ただ、やろうと思えばここまでできる、というわけですね。

---

さて、ここまで、MNIST のサンプルを CPU 側で動かす方法と、GPU 側で動かす方法と、２種類のアプローチを見てきました。

ここで Barracuda のバックエンドの構成について簡単に説明しておきたいと思います。

---

Barracuda 内で推論処理を行うバックエンドの実装には、次の６種類があります。

CSharpRef は、ナイーブな C# で書かれたリファレンス実装です。

これは主にテスト用ですので、みなさんが使う機会は無いと思います。

---

CSharp は高速な C# 実装です。

WebGL を含む全てのプラットフォームで動作するので、なるべく多くのプラットフォームをカバーしたい場合に使います。

ビルド時は IL2CPP による高速化が期待できます。

---

CSharpBurst は Burst コンパイラを使用したバックエンドです。

Burst について念のため補足しておくと、自動ベクトル化や並行処理をサポートしたハイパフォーマンスな C# 処理系です。

CPU 側で動かす場合は、これがもっとも高速な実装になりますが、 Burst 非対応のプラットフォームでは使えません。例えば WebGL などは対応不可です。

---

ComputeRef は GPU 用のリファレンス実装です。これも皆さんが使う機会は無いと思います。

GPU 上で動く実装として Compute と ComputePrecompiled がありますが、このふたつは GPU 上でのパフォーマンスは差がありません。

---

ComputePrecompiled は CPU 側の負荷を減らすための最適化を含んでいます。

通常はこちらを使用してください。

---

なお、これらの GPU 実装を動かすには、プラットフォームが Compute Shader に対応している必要があります。

PC や Mac であれば、まず確実に対応しているはずです。

モバイルの場合は、Metal や Vulkan であれば動作しますが、OpenGL ES では動かない可能性もあります。

---

まとめると、比較的パワーのある環境では ComputePrecompiled を使用し、 OpenGL ES 等のレガシー環境では CSharpBurst を使用し、 WebGL まで含める場合は CSharp を使用する、と言うような順序で選択することになるかと思います。

---

ここから、僕が Barracuda 上で動作を確認したいくつかのモデルを紹介したいと思います。

---

まず最初は、アニメ絵に特化した超解像フィルタとして有名な Waifu2x です。

古典的ですがいまだ強い人気のあるフィルタです。

---

次は BodyPix という、人体に特化したセマンティックセグメンテーションを行うモデルです。

ポーズ解析のためのキーポイント検出も備えていて、何にでも使えるとても便利な万能モデルです。

このモデルについては以前、別の動画でも解説を行いました。

興味のある方は是非ご覧ください。

---

冒頭でも紹介した MediaPipe の Selfie モデルです。

バーチャル背景に使えます。

とても高速に動きます。

---

これは M-LSD という、ライン・セグメント・デテクション、線分検出モデルです。

任意の画像からワイヤフレーム的な構造を抽出できます。

---

冒頭でも紹介した YOLOv4 tiny モデルです。これともう一つ……

---

YOLOv2 の tiny モデルも Barracuda で動かしてみました。

YOLOv2 の方が精度は低いですが、 YOLO シリーズの中ではもっとも軽量なモデルなので、用途次第ではまだ役に立つかもしれません。

---

これは Ultra Face と言う顔検出フィルタです。大量の顔をかなり正確に検出できます。
こちらの BlazeFace はもう少し一般的な顔フィルタです。非常に高速に動作するので、この後に紹介する顔解析モデルの前処理フィルタとして使えます。
これは MediaPipe の顔のランドマークを検出するモデルです。顔の動きの分析に使用できます。
こちらは瞼と瞳の分析に特化したモデルですね。そしてこれらのモデルを組み合わせることにより……
フェーシャルトラッキングのパイプラインが実現できます。このサンプルは GPU 上でパイプラインを構築しており、非常に高速に動作します。
この BlazePalm は手のひらを検出するモデルですね。 BlazeFace と同じく、前処理用のフィルタとして使える軽量なモデルです。
そしてこれは手のランドマークを検出するモデルです。これらのモデルを組み合わせることにより……
ハンドトラッキングのパイプラインが実現できます。これも GPU 上でパイプラインを構築しました。
以上、色々なモデルを紹介しましたが、コンピュータビジョン系のモデルに偏っているのは、僕の個人的な好みであって、他意はありません。
自然言語処理や音声解析などにも同様に使用できるはずです。
今後機会があれば、それらのモデルも試してみたいと考えています。
ONNX と Barracuda の現実
このように夢のある Barracuda と ONNX の話をしてきたわけですが、現実的な話をすると、そうおいしいことばかりではありません。
まず残念なのは、すべての ONNX モデルがうまく動いてくれるというわけではない、という事実です。
というか、既存の学習済みモデルを使おうとすると、うまく行かないケースの方が多いです。
一発で動いてくれるのは、むしろ稀なケースです。
理由は色々ありますが、 ONNX の互換性の問題、Opset バージョンの整合性の問題、 Barracuda の未対応オペレーターの問題、カスタムオペレーターはもちろんダメですね、あと細かな未実装機能、単なるバグ、などなど、様々な問題にぶち当たることになります。
具体的な例をみてみましょう。
これは先ほど紹介した M-LSD 線分検出モデルですが、互換性の問題があり、当初 Barracuda で使うことができませんでした。
まず最初の問題は Split オペレーターの仕様です。
これは ONNX のすごく細かい話になってくるのですが、最新の ONNX の仕様では、テンソルをどのような配分で分割するかという指定……この split 入力ですね、これを明示的に行わなくても、デフォルトの挙動で補ってくれるようになっています。
ただ Barracuda はこれに非対応なうえ古い仕様になっており、split をアトリビュートとして与える必要があります。
そのためエラーになってしまいました。
もう一つの問題はネットワークの後半にある TopK オペレーターです。
現状の Barracuda は一応 TopK に対応しています。
しかし、残念ながら実装が完全ではなく、エラーを起こすことがあります。
今回もこれを正常に動作させることができませんでした。
と言うことで、この M-LSD は Barracuda で動きませんよ……となってしまうのですが、頑張って対処すれば動かすことも可能です。
例えば Split オペレーターの問題については、明示的にアトリビュートを渡すように改造すれば回避できます。
Python の ONNX モジュールを使って、これを修正するコードを組んでみました。
単純にグラフをなぞって Split オペレーターを探して、アトリビュートを追加するだけの内容です。
次は TopK オペレーターです。
Netron でネットワークを覗いてみると、 TopK はここにあります。
これは恐らく、スコア値を基準として検出候補の絞り込みを行う処理です。
これより後のサブネットワークは、出力データの整形を行っているだけですね。
この手のポストプロセス処理は Compute Shader で簡単に書けます。
というかそもそも TopK を使わなくても、閾値によるフィルタと NMS で十分な気もしますので、その方向で改造することにしました。
ノードの削除にも Python の ONNX モジュールを使いました。
TopK 以降のサブネットワークを削除する処理です。
ちょっとややこしくて、ぱっと見で分かりにくいですね……
ONNX ファイルの中身は Protocol Buffer なので、 protobuf を使い慣れてる方なら、もっとスッと書く方法が思いつくかもしれません。
僕がぬるっと書くとこうなりました。
こんな感じで書いた Python を Google Colaboratory 上で動かしてコンバートしました。
これでようやくBarracuda 上で使えるようになったというわけです。
このプロジェクトはこちらのリポジトリで公開しています。
こんな感じで、調整すれば動くんだけど、未調整で何でも動かせるかというと、そうではない、と言うのが Barracuda の現状です。
独自のモデルを構築する際には、使用する機能が Barracuda で対応済みかどうか確認しておく必要がありますし、学習済みのモデルを使用する際には、今回やったような調整が必要になるかもしれません。
まとめ
このように色々課題もあるんですが、 ONNX のような共通規格で出力された学習済みモデルをマルチプラットフォームに展開でき、高パフォーマンスで動かすことができるというのは、大きな強みです。
一般アプリにおける機械学習モデルの利用を考える際には、簡易的に使用できるソリューションのひとつとして、ぜひ候補に入れていただければと思います。

</textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        ratio: '16:9',
        highlightStyle: 'sunburst',
        slideNumberFormat: ''
      });
    </script>
  </body>
</html>
