<!DOCTYPE html>
<html>
  <head>
    <title>98 Barracuda ONNX</title>
    <meta charset="utf-8">
    <style>
      .remark-slide-content {
        color: white;
        background-color: black;
        font-size: 50pt;
        padding: 0px 0.5em;
      }
      .remark-code-line { font-size: 25pt; margin: 0.2em 0px; }
      p { margin: 0.5em 0px; line-height: 120%; }
      code { margin: 0px 2em; }
    </style>
  </head>
  <body>
<textarea id="source">

皆さんこんにちは。

ユニティー・テクノロジーズ・ジャパン、アドボケイトの高橋です。

---

この講演では、Unity が提供する機械学習パッケージの一つである Barracuda について紹介します。

---

Unity で機械学習というと ml-agents の方が有名ですが、 Barracuda はそのランタイム部分に相当するもので、アプリケーション開発者の皆さんにとっては、より身近な存在になるかもしれません。

---

Barracuda とは
Barracuda とは、一言で説明すると、 Unity 上で動作する ONNX -- ONNX ランタイムです。 
ONNX 形式でエクスポートされた学習済みモデルを Unity 上で動かすことができるようになります。
早速ですが、実際に動いている所を見てもらいましょう。
まずはオブジェクト検出モデルとしてお馴染みの YOLO を動かしてみました。
具体的には YOLOv4 の Tiny モデルになります。
この PC は GeForce RTX 2060 SUPER を搭載していますが、だいたい 240 fps ぐらいで動いています。
次は MediaPipe の FaceMesh パイプラインを動かしてみました。
顔検出、ランドマーク検出、瞳検出などの複数のモデルを組み合わせることで、フェーシャルトラッキングを実現しています。
次は同じく MediaPipe から Selfie モデルです。
これはヒューマンセグメンテーションを行うモデルで、要するにビデオチャットのバーチャル背景みたいなやつです。
すごく軽量なモデルで、 PC 上では 400 fps 以上で動いています。
同じプロジェクトを iPhone X 上で動かしてみました。
こちらも 60fps で動かすことができています。
このようにプラットフォームを跨いで同じモデルを使いまわせるのは、 Barracuda の強みのひとつです。
ONNX とは
では、さっそく Barracuda の説明に……といきたいところなのですが、まずは ONNX について話しておきましょう。
機械学習に取り組んでいる方なら、既にご存知かもしれませんし、名前ぐらいは聞いたことがあるかもしれません。
ONNX は、すごくぶっちゃけて言うと、機械学習モデルの共通ファイルフォーマットです。
ONNX のホームページを覗いてみると、 ONNX は AI 開発者のためのオープンエコシステムであって……云々……と言うようなことが書いてあるので、これを単にファイルフォーマットです！と言ったら怒られてしまうかもしれませんが……まあぶっちゃけるとファイルフォーマットです。
機械学習には TensorFlow や PyTorch など様々なライブラリがありますが、生成されたモデルを ONNX 形式で出力することによって、様々なランタイムで使いまわすことができるようになります。
そして Barracuda を使えば、この ONNX ファイルを、 Unity 上でも扱うことができるようになる、というわけですね。
Unity 上で ONNX を使ってみよう
ここにサンプルとして作成した小さな ONNX ファイルがあります。
中身はこんな感じです。
これを Unity にドラッグ＆ドロップ。
これでインポート完了です。
Barracuda は Netron に対応していて、インポートしたファイルをダブルクリックで開けます。
また、インスペクタからこのボタンを押すことで、 Barracudaの 内部表現を確認することもできます。
ちなみに、これ、 Netron と言うツールです。
ニューラルネットの視覚化ツールで、めちゃくちゃ便利なので必ずインストールしましょう。
有名なツールかなと思ったんですが、これって何ですか？と質問されることがよくあるので、ここで敢えて紹介しておきます。 Netron です。
で、こうして ONNX ファイルのネットワークと、 Barracuda の内部表現を比較してみると、構造がだいぶ異なっていることが分かります。
Barracuda はインポート時に最適化を行うので、こんな風に異なった内部表現に変化することがあるんですね。
具体的には、事前計算可能な部分が結合されたり、２回行ってるトランスポーズが不要になるよう調整されたり、コンボリューションとバイアスとアクティベーターが一括化されたり、とか、そういうのですね。
実際に Barracuda を使用するサンプルコードも見てみましょう。
これは皆さんお馴染み MNIST 手書き認識モデルを動かすサンプルです。
こちらのリポジトリで公開しています。
主なコードは MnistTest.cs 内にあります。
中身はこんな感じです。
ごく普通の作りをした API なので、この手のライブラリを使ったことのある方なら、なんなく使えると思います。
入力用のテンソルを作成して、多次元配列的にアクセスしてデータを埋めて、ワーカーインスタンスを作って走らせて、結果をテンソルから取り出して SoftMax をかけて……とそんな感じですね。
ちなみにここではワーカーの種類は CPU を指定していますが、ここを GPU にすれば、 Compute Shader を利用して動く GPU ワーカーを使用できます。
こんな感じで簡単に使うこともできるんですが、このような画像処理のプリプロセスをシングルスレッドのナイーブな C# で動かすのは、ちょっと心許ないですよね。
この MNIST のモデルは入力がたかだか 28x28 なので、まあいいかという感じなんですが、例えばこれが 512x512x3 なんかになってくると話が変わってきます。
このような場合は Compute Shader を使って GPU 側でプリプロセスした方がいいでしょう。
それでは、同じ MNIST のモデルを、なるべく GPU 側でパイプラインを動かすよう、実装し直してみます。こんな感じです。
まず最初に、画像のテクスチャをコンピュートシェーダーに渡して Dispatch しています。
シェーダーの中身は、テクスチャをサンプルしてから、コンピュートバッファに詰め込むだけの、ごく単純なものなので、ここでは省略します。
次はここ、入力用のテンソルを作成し、ワーカーを動かしています。
テンソルのコンストラクタに先ほどのコンピュートバッファを渡しています。コンピュートバッファをストレージとしたテンソルを作成しているわけです。
ちなみに、ワーカーの種類は、デフォルトとして GPU ワーカーが選択されることを想定して、記述を省略しています。
本当は明示的に指定した方がいいんですが、画面が狭いので省略しちゃいました。
推論結果は１０チャンネルのテンソルとなりますが、テクスチャとして扱う場合は、シングルチャンネルで横幅１０ピクセルとした方が扱いやすいので、そのようにリシェイプしてからコピーしています。
そしてポストプロセスをコンピュートシェーダーで実行しています。
結果はコンピュートバッファに格納されます。
こうして得られたコンピュートバッファは、 CPU を経由せずに、そのまま描画パイプラインに流すことができます。
つまり、入力から出力まで、一切 CPU 側にデータを戻すことなく、 GPU 側で処理を完結させることができるというわけです。
まあ実際には、推論結果を CPU 側に戻さず完結させることってあんまりないと思うんですが、やろうと思えばここまでできるって感じですね。
ちなみにこの GPU 最適化バージョンのサンプルはこちらのリポジトリにあります。
Barracuda バックエンドの種類
ここまで、MNIST のサンプルを CPU 側で動かす流れと、 GPU 側で動かす流れと、２通り見てきましたが、ここで Barracuda のバックエンドの構成について簡単に説明しておきたいと思います。
Barracuda 内で推論処理を行うバックエンドの実装には、次の６種類があります。
CSharpRef は、ナイーブな C# で書かれたリファレンス実装です。
これは主にテスト用ですので、みなさんが使う機会は無いと思います。
CSharp は高速な C# 実装です。 WebGL を含む全てのプラットフォームで動作するので、なるべく多くのプラットフォームをカバーしたい場合に使います。ビルド時は IL2CPP による高速化が期待できます。
CSharpBurst は Burst コンパイラを使用したバックエンドです。 Burst について念のため補足しておくと、自動ベクトル化や並行処理をサポートしたハイパフォーマンスな C# 処理系です。CPU 側で動かす場合は、これがもっとも高速な実装になりますが、 Burst 非対応のプラットフォームでは使えません。例えば WebGL などは対応不可です。
ComputeRef は GPU 用のリファレンス実装です。これも皆さんが使う機会は無いと思います。
GPU 上で動く実装として Compute と ComputePrecompiled がありますが、このふたつは GPU 上でのパフォーマンスは差がありません。
ComputePrecompiled は CPU 側の負荷を減らすための最適化を含んでいます。通常はこちらを使用してください。
なお、これらの GPU 実装を動かすには、プラットフォームが Compute Shader に対応している必要があります。
PC や Mac であれば、まず確実に対応しているはずです。
モバイルの場合は、 Metal や Vulkan であれば動作しますが、 OpenGL ES には非対応です。
まとめると、比較的パワーのある環境では ComputePrecompiled を使用し、 OpenGL ES 等のレガシー環境では CSharpBurst を使用し、 WebGL まで含める場合は CSharp を使用する、と言うような順序で選択することになるかと思います。
サンプル紹介
ここから、僕が Barracuda 上で動作を確認したいくつかのモデルを紹介したいと思います。
まず最初は、アニメ絵に特化した超解像フィルタとして有名な Waifu2x です。古典的ですがいまだ強い人気のあるフィルタです。
次は BodyPix という、人体に特化したセマンティックセグメンテーションを行うモデルです。ポーズ解析のためのキーポイント検出も備えていて、何にでも使えるとても便利な万能モデルです。僕もいろんなプロジェクトで使用しています。
冒頭でも紹介した MediaPipe の Selfie モデルです。バーチャル背景に使えます。とても高速に動きます。
これは M-LSD という、ライン・セグメント・デテクション、線分検出モデルです。任意の画像からワイヤフレーム的な構造を抽出できます。
冒頭でも紹介した YOLOv4 tiny モデルです。これともう一つ……
YOLOv2 の tiny モデルも Barracuda で動かしてみました。 YOLOv2 の方が精度は低いですが、 YOLO シリーズの中ではもっとも軽量なモデルなので、用途次第ではまだ役に立つかもしれません。
これは Ultra Face と言う顔検出フィルタです。大量の顔をかなり正確に検出できます。
こちらの BlazeFace はもう少し一般的な顔フィルタです。非常に高速に動作するので、この後に紹介する顔解析モデルの前処理フィルタとして使えます。
これは MediaPipe の顔のランドマークを検出するモデルです。顔の動きの分析に使用できます。
こちらは瞼と瞳の分析に特化したモデルですね。そしてこれらのモデルを組み合わせることにより……
フェーシャルトラッキングのパイプラインが実現できます。このサンプルは GPU 上でパイプラインを構築しており、非常に高速に動作します。
この BlazePalm は手のひらを検出するモデルですね。 BlazeFace と同じく、前処理用のフィルタとして使える軽量なモデルです。
そしてこれは手のランドマークを検出するモデルです。これらのモデルを組み合わせることにより……
ハンドトラッキングのパイプラインが実現できます。これも GPU 上でパイプラインを構築しました。
以上、色々なモデルを紹介しましたが、コンピュータビジョン系のモデルに偏っているのは、僕の個人的な好みであって、他意はありません。
自然言語処理や音声解析などにも同様に使用できるはずです。
今後機会があれば、それらのモデルも試してみたいと考えています。
ONNX と Barracuda の現実
このように夢のある Barracuda と ONNX の話をしてきたわけですが、現実的な話をすると、そうおいしいことばかりではありません。
まず残念なのは、すべての ONNX モデルがうまく動いてくれるというわけではない、という事実です。
というか、既存の学習済みモデルを使おうとすると、うまく行かないケースの方が多いです。
一発で動いてくれるのは、むしろ稀なケースです。
理由は色々ありますが、 ONNX の互換性の問題、Opset バージョンの整合性の問題、 Barracuda の未対応オペレーターの問題、カスタムオペレーターはもちろんダメですね、あと細かな未実装機能、単なるバグ、などなど、様々な問題にぶち当たることになります。
具体的な例をみてみましょう。
これは先ほど紹介した M-LSD 線分検出モデルですが、互換性の問題があり、当初 Barracuda で使うことができませんでした。
まず最初の問題は Split オペレーターの仕様です。
これは ONNX のすごく細かい話になってくるのですが、最新の ONNX の仕様では、テンソルをどのような配分で分割するかという指定……この split 入力ですね、これを明示的に行わなくても、デフォルトの挙動で補ってくれるようになっています。
ただ Barracuda はこれに非対応なうえ古い仕様になっており、split をアトリビュートとして与える必要があります。
そのためエラーになってしまいました。
もう一つの問題はネットワークの後半にある TopK オペレーターです。
現状の Barracuda は一応 TopK に対応しています。
しかし、残念ながら実装が完全ではなく、エラーを起こすことがあります。
今回もこれを正常に動作させることができませんでした。
と言うことで、この M-LSD は Barracuda で動きませんよ……となってしまうのですが、頑張って対処すれば動かすことも可能です。
例えば Split オペレーターの問題については、明示的にアトリビュートを渡すように改造すれば回避できます。
Python の ONNX モジュールを使って、これを修正するコードを組んでみました。
単純にグラフをなぞって Split オペレーターを探して、アトリビュートを追加するだけの内容です。
次は TopK オペレーターです。
Netron でネットワークを覗いてみると、 TopK はここにあります。
これは恐らく、スコア値を基準として検出候補の絞り込みを行う処理です。
これより後のサブネットワークは、出力データの整形を行っているだけですね。
この手のポストプロセス処理は Compute Shader で簡単に書けます。
というかそもそも TopK を使わなくても、閾値によるフィルタと NMS で十分な気もしますので、その方向で改造することにしました。
ノードの削除にも Python の ONNX モジュールを使いました。
TopK 以降のサブネットワークを削除する処理です。
ちょっとややこしくて、ぱっと見で分かりにくいですね……
ONNX ファイルの中身は Protocol Buffer なので、 protobuf を使い慣れてる方なら、もっとスッと書く方法が思いつくかもしれません。
僕がぬるっと書くとこうなりました。
こんな感じで書いた Python を Google Colaboratory 上で動かしてコンバートしました。
これでようやくBarracuda 上で使えるようになったというわけです。
このプロジェクトはこちらのリポジトリで公開しています。
こんな感じで、調整すれば動くんだけど、未調整で何でも動かせるかというと、そうではない、と言うのが Barracuda の現状です。
独自のモデルを構築する際には、使用する機能が Barracuda で対応済みかどうか確認しておく必要がありますし、学習済みのモデルを使用する際には、今回やったような調整が必要になるかもしれません。
まとめ
このように色々課題もあるんですが、 ONNX のような共通規格で出力された学習済みモデルをマルチプラットフォームに展開でき、高パフォーマンスで動かすことができるというのは、大きな強みです。
一般アプリにおける機械学習モデルの利用を考える際には、簡易的に使用できるソリューションのひとつとして、ぜひ候補に入れていただければと思います。

</textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({
        ratio: '16:9',
        highlightStyle: 'sunburst',
        slideNumberFormat: ''
      });
    </script>
  </body>
</html>
